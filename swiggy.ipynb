{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9dadb0be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: d:\\GuviDatascienceCourse\\Project\\4thProject(Swiggy’s Restaurant Recommendation System using Streamlit\\ProjectTopicsWise\\Streamlit\n",
      "Data dir: d:\\GuviDatascienceCourse\\Project\\4thProject(Swiggy’s Restaurant Recommendation System using Streamlit\\ProjectTopicsWise\\Streamlit\\data\n",
      "Models dir: d:\\GuviDatascienceCourse\\Project\\4thProject(Swiggy’s Restaurant Recommendation System using Streamlit\\ProjectTopicsWise\\Streamlit\\models\n"
     ]
    }
   ],
   "source": [
    "# === 1. Imports and settings ===\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import MultiLabelBinarizer, StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import pickle\n",
    "import random\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "random.seed(RANDOM_STATE)\n",
    "\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "data_dir = os.path.join(project_root, \"data\")\n",
    "models_dir = os.path.join(project_root, \"models\")\n",
    "\n",
    "os.makedirs(data_dir, exist_ok=True)\n",
    "os.makedirs(models_dir, exist_ok=True)\n",
    "\n",
    "print(\"Project root:\", project_root)\n",
    "print(\"Data dir:\", data_dir)\n",
    "print(\"Models dir:\", models_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0552bada",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw shape: (148541, 11)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>city</th>\n",
       "      <th>rating</th>\n",
       "      <th>rating_count</th>\n",
       "      <th>cost</th>\n",
       "      <th>cuisine</th>\n",
       "      <th>lic_no</th>\n",
       "      <th>link</th>\n",
       "      <th>address</th>\n",
       "      <th>menu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>567335</td>\n",
       "      <td>AB FOODS POINT</td>\n",
       "      <td>Abohar</td>\n",
       "      <td>--</td>\n",
       "      <td>Too Few Ratings</td>\n",
       "      <td>₹ 200</td>\n",
       "      <td>Beverages,Pizzas</td>\n",
       "      <td>22122652000138</td>\n",
       "      <td>https://www.swiggy.com/restaurants/ab-foods-po...</td>\n",
       "      <td>AB FOODS POINT, NEAR RISHI NARANG DENTAL CLINI...</td>\n",
       "      <td>Menu/567335.json</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>531342</td>\n",
       "      <td>Janta Sweet House</td>\n",
       "      <td>Abohar</td>\n",
       "      <td>4.4</td>\n",
       "      <td>50+ ratings</td>\n",
       "      <td>₹ 200</td>\n",
       "      <td>Sweets,Bakery</td>\n",
       "      <td>12117201000112</td>\n",
       "      <td>https://www.swiggy.com/restaurants/janta-sweet...</td>\n",
       "      <td>Janta Sweet House, Bazar No.9, Circullar Road,...</td>\n",
       "      <td>Menu/531342.json</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>158203</td>\n",
       "      <td>theka coffee desi</td>\n",
       "      <td>Abohar</td>\n",
       "      <td>3.8</td>\n",
       "      <td>100+ ratings</td>\n",
       "      <td>₹ 100</td>\n",
       "      <td>Beverages</td>\n",
       "      <td>22121652000190</td>\n",
       "      <td>https://www.swiggy.com/restaurants/theka-coffe...</td>\n",
       "      <td>theka coffee desi, sahtiya sadan road city</td>\n",
       "      <td>Menu/158203.json</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>187912</td>\n",
       "      <td>Singh Hut</td>\n",
       "      <td>Abohar</td>\n",
       "      <td>3.7</td>\n",
       "      <td>20+ ratings</td>\n",
       "      <td>₹ 250</td>\n",
       "      <td>Fast Food,Indian</td>\n",
       "      <td>22119652000167</td>\n",
       "      <td>https://www.swiggy.com/restaurants/singh-hut-n...</td>\n",
       "      <td>Singh Hut, CIRCULAR ROAD NEAR NEHRU PARK ABOHAR</td>\n",
       "      <td>Menu/187912.json</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>543530</td>\n",
       "      <td>GRILL MASTERS</td>\n",
       "      <td>Abohar</td>\n",
       "      <td>--</td>\n",
       "      <td>Too Few Ratings</td>\n",
       "      <td>₹ 250</td>\n",
       "      <td>Italian-American,Fast Food</td>\n",
       "      <td>12122201000053</td>\n",
       "      <td>https://www.swiggy.com/restaurants/grill-maste...</td>\n",
       "      <td>GRILL MASTERS, ADA Heights, Abohar - Hanumanga...</td>\n",
       "      <td>Menu/543530.json</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id               name    city rating     rating_count   cost  \\\n",
       "0  567335     AB FOODS POINT  Abohar     --  Too Few Ratings  ₹ 200   \n",
       "1  531342  Janta Sweet House  Abohar    4.4      50+ ratings  ₹ 200   \n",
       "2  158203  theka coffee desi  Abohar    3.8     100+ ratings  ₹ 100   \n",
       "3  187912          Singh Hut  Abohar    3.7      20+ ratings  ₹ 250   \n",
       "4  543530      GRILL MASTERS  Abohar     --  Too Few Ratings  ₹ 250   \n",
       "\n",
       "                      cuisine          lic_no  \\\n",
       "0            Beverages,Pizzas  22122652000138   \n",
       "1               Sweets,Bakery  12117201000112   \n",
       "2                   Beverages  22121652000190   \n",
       "3            Fast Food,Indian  22119652000167   \n",
       "4  Italian-American,Fast Food  12122201000053   \n",
       "\n",
       "                                                link  \\\n",
       "0  https://www.swiggy.com/restaurants/ab-foods-po...   \n",
       "1  https://www.swiggy.com/restaurants/janta-sweet...   \n",
       "2  https://www.swiggy.com/restaurants/theka-coffe...   \n",
       "3  https://www.swiggy.com/restaurants/singh-hut-n...   \n",
       "4  https://www.swiggy.com/restaurants/grill-maste...   \n",
       "\n",
       "                                             address              menu  \n",
       "0  AB FOODS POINT, NEAR RISHI NARANG DENTAL CLINI...  Menu/567335.json  \n",
       "1  Janta Sweet House, Bazar No.9, Circullar Road,...  Menu/531342.json  \n",
       "2         theka coffee desi, sahtiya sadan road city  Menu/158203.json  \n",
       "3    Singh Hut, CIRCULAR ROAD NEAR NEHRU PARK ABOHAR  Menu/187912.json  \n",
       "4  GRILL MASTERS, ADA Heights, Abohar - Hanumanga...  Menu/543530.json  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# === 2. Load raw data ===\n",
    "\n",
    "csv_path = os.path.join(data_dir, \"swiggy.csv\")\n",
    "df_raw = pd.read_csv(csv_path)\n",
    "\n",
    "print(\"Raw shape:\", df_raw.shape)\n",
    "df_raw.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7d145306",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns after drop: ['id', 'name', 'city', 'rating', 'rating_count', 'cost', 'cuisine']\n",
      "Duplicates removed: 0\n",
      "Rows dropped where all numeric fields missing: 115\n",
      "Shape after final cleaning: (148414, 7)\n",
      "Saved cleaned data to: d:\\GuviDatascienceCourse\\Project\\4thProject(Swiggy’s Restaurant Recommendation System using Streamlit\\ProjectTopicsWise\\Streamlit\\data\\cleaned_data.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# === 3. Data understanding and cleaning ===\n",
    "# Columns (from problem): \n",
    "# ['id','name','city','rating','rating_count','cost','cuisine','lic_no','link','address','menu']\n",
    "\n",
    "df = df_raw.copy()\n",
    "\n",
    "# Drop columns: do NOT consider menu, address, link, lic_no\n",
    "cols_to_drop = [\"menu\", \"address\", \"link\", \"lic_no\"]\n",
    "for c in cols_to_drop:\n",
    "    if c in df.columns:\n",
    "        df.drop(columns=c, inplace=True)\n",
    "\n",
    "print(\"Columns after drop:\", df.columns.tolist())\n",
    "\n",
    "# 3.1 Remove duplicates\n",
    "before_dups = df.shape[0]\n",
    "df = df.drop_duplicates()\n",
    "after_dups = df.shape[0]\n",
    "print(f\"Duplicates removed: {before_dups - after_dups}\")\n",
    "\n",
    "# 3.2 Handle missing values:\n",
    "# rating: may have '--'\n",
    "# rating_count: e.g. \"Too Few Ratings\", \"50+ ratings\"\n",
    "# cost: e.g. '₹ 200'\n",
    "\n",
    "# Clean rating: convert '--' to NaN, then to float\n",
    "def clean_rating(x):\n",
    "    try:\n",
    "        x = str(x).strip()\n",
    "        if x == \"--\" or x == \"\":\n",
    "            return np.nan\n",
    "        return float(x)\n",
    "    except Exception:\n",
    "        return np.nan\n",
    "\n",
    "df[\"rating\"] = df[\"rating\"].apply(clean_rating)   #rating_clean\n",
    "\n",
    "# Clean rating_count: extract leading number\n",
    "import re\n",
    "def clean_rating_count(x):\n",
    "    x = str(x)\n",
    "    if \"Too Few\" in x or x.strip() == \"\":\n",
    "        return np.nan\n",
    "    match = re.search(r\"\\d+\", x)\n",
    "    if match:\n",
    "        return int(match.group())\n",
    "    return np.nan\n",
    "\n",
    "df[\"rating_count\"] = df[\"rating_count\"].apply(clean_rating_count)    #rating_count_clean\n",
    "\n",
    "# Clean cost: remove currency and commas\n",
    "def clean_cost(x):\n",
    "    x = str(x)\n",
    "    x = x.replace(\"₹\", \"\").replace(\",\", \"\").strip()\n",
    "    if x == \"\":\n",
    "        return np.nan\n",
    "    try:\n",
    "        return float(x)\n",
    "    except Exception:\n",
    "        return np.nan\n",
    "\n",
    "df[\"cost\"] = df[\"cost\"].apply(clean_cost) #cost_clean\t\n",
    "\n",
    "# Drop original numeric-ish columns if you only want clean versions in modelling\n",
    "# (keep originals for report if you want)\n",
    "# For modelling we will use rating_clean, rating_count_clean, cost_clean\n",
    "num_cols = [\"rating\", \"rating_count\", \"cost\"]    #rating_clean,rating_count_clean,cost_clean\t\n",
    "\n",
    "# Basic missing handling: drop rows where all 3 numeric fields are NaN\n",
    "before_na = df.shape[0]\n",
    "df = df.dropna(subset=num_cols, how=\"all\")\n",
    "after_na = df.shape[0]\n",
    "print(f\"Rows dropped where all numeric fields missing: {before_na - after_na}\")\n",
    "\n",
    "# For remaining NaNs, we can impute with median\n",
    "for col in num_cols:\n",
    "    median_val = df[col].median()\n",
    "    df[col] = df[col].fillna(median_val)\n",
    "\n",
    "# Final cleaning: ensure basic non-null in key columns\n",
    "df = df.dropna(subset=[\"city\", \"cuisine\", \"name\"])\n",
    "print(\"Shape after final cleaning:\", df.shape)\n",
    "\n",
    "# Save cleaned_data.csv (keeping original descriptive columns)\n",
    "cleaned_path = os.path.join(data_dir, \"cleaned_data.csv\")\n",
    "df.to_csv(cleaned_path, index=False)\n",
    "print(\"Saved cleaned data to:\", cleaned_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "98d57159",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cuisine encoded shape: (148414, 126)\n",
      "City encoded shape: (148414, 821)\n",
      "Encoded data shape: (148414, 950)\n",
      "Saved encoded data to: d:\\GuviDatascienceCourse\\Project\\4thProject(Swiggy’s Restaurant Recommendation System using Streamlit\\ProjectTopicsWise\\Streamlit\\data\\encoded_data.csv\n",
      "Saved MultiLabelBinarizer to: d:\\GuviDatascienceCourse\\Project\\4thProject(Swiggy’s Restaurant Recommendation System using Streamlit\\ProjectTopicsWise\\Streamlit\\models\\mlb_cuisine.pkl\n"
     ]
    }
   ],
   "source": [
    "# === 4. Preprocessing: MultiLabelBinarizer for cuisine, and encoding city ===\n",
    "\n",
    "# cuisine is multi-label string like \"Beverages,Pizzas\"\n",
    "# Use MultiLabelBinarizer instead of OneHotEncoder\n",
    "\n",
    "df_prep = df.copy()\n",
    "\n",
    "# 4.1 MultiLabelBinarizer for cuisine\n",
    "mlb = MultiLabelBinarizer()\n",
    "\n",
    "def split_cuisine(val):\n",
    "    # val is like \"North Indian,Chinese\"\n",
    "    if pd.isna(val):\n",
    "        return []\n",
    "    return [c.strip() for c in str(val).split(\",\") if c.strip() != \"\"]\n",
    "\n",
    "cuisine_lists = df_prep[\"cuisine\"].apply(split_cuisine)\n",
    "cuisine_encoded = mlb.fit_transform(cuisine_lists)\n",
    "\n",
    "cuisine_df = pd.DataFrame(\n",
    "    cuisine_encoded,\n",
    "    columns=[f\"cuisine_{c}\" for c in mlb.classes_],\n",
    "    index=df_prep.index\n",
    ")\n",
    "\n",
    "print(\"Cuisine encoded shape:\", cuisine_df.shape)\n",
    "\n",
    "# 4.2 City encoding: simple one-hot via pandas.get_dummies\n",
    "city_dummies = pd.get_dummies(df_prep[\"city\"], prefix=\"city\")\n",
    "print(\"City encoded shape:\", city_dummies.shape)\n",
    "\n",
    "# 4.3 Combine numeric + city + cuisine\n",
    "numeric_df = df_prep[[\"rating\", \"rating_count\", \"cost\"]]   #rating_clean,rating_count_clean,cost_clean\t\n",
    "\n",
    "encoded_df = pd.concat([numeric_df, city_dummies, cuisine_df], axis=1)\n",
    "\n",
    "print(\"Encoded data shape:\", encoded_df.shape)\n",
    "\n",
    "# Ensure indices match between cleaned_data and encoded_data\n",
    "assert (encoded_df.index == df_prep.index).all(), \"Index mismatch between cleaned and encoded data\"\n",
    "\n",
    "encoded_path = os.path.join(data_dir, \"encoded_data.csv\")\n",
    "encoded_df.to_csv(encoded_path, index=False)\n",
    "print(\"Saved encoded data to:\", encoded_path)\n",
    "\n",
    "# Save encoder (mlb) for use in Streamlit app\n",
    "mlb_path = os.path.join(models_dir, \"mlb_cuisine.pkl\")\n",
    "with open(mlb_path, \"wb\") as f:\n",
    "    pickle.dump(mlb, f)\n",
    "\n",
    "print(\"Saved MultiLabelBinarizer to:\", mlb_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "373d66c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaler fitted and saved to: d:\\GuviDatascienceCourse\\Project\\4thProject(Swiggy’s Restaurant Recommendation System using Streamlit\\ProjectTopicsWise\\Streamlit\\models\\scaler.pkl\n",
      "Scaled feature matrix shape: (148414, 950)\n"
     ]
    }
   ],
   "source": [
    "# === 5. Feature scaling ===\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(encoded_df)\n",
    "\n",
    "scaler_path = os.path.join(models_dir, \"scaler.pkl\")\n",
    "with open(scaler_path, \"wb\") as f:\n",
    "    pickle.dump(scaler, f)\n",
    "\n",
    "print(\"Scaler fitted and saved to:\", scaler_path)\n",
    "print(\"Scaled feature matrix shape:\", X_scaled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0f416e4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KMeans trained with 20 clusters and saved to: d:\\GuviDatascienceCourse\\Project\\4thProject(Swiggy’s Restaurant Recommendation System using Streamlit\\ProjectTopicsWise\\Streamlit\\models\\kmeans_model.pkl\n",
      "NearestNeighbors model saved to: d:\\GuviDatascienceCourse\\Project\\4thProject(Swiggy’s Restaurant Recommendation System using Streamlit\\ProjectTopicsWise\\Streamlit\\models\\nn_model.pkl\n"
     ]
    }
   ],
   "source": [
    "# === 6. Unsupervised recommendation engine: KMeans + cosine similarity / nearest neighbors ===\n",
    "\n",
    "# Choose number of clusters (heuristic; you could do elbow method)\n",
    "n_clusters = 20  # adjust if needed\n",
    "\n",
    "kmeans = KMeans(\n",
    "    n_clusters=n_clusters,\n",
    "    random_state=RANDOM_STATE,\n",
    "    n_init=10\n",
    ")\n",
    "kmeans.fit(X_scaled)\n",
    "\n",
    "kmeans_path = os.path.join(models_dir, \"kmeans_model.pkl\")\n",
    "with open(kmeans_path, \"wb\") as f:\n",
    "    pickle.dump(kmeans, f)\n",
    "\n",
    "print(\"KMeans trained with\", n_clusters, \"clusters and saved to:\", kmeans_path)\n",
    "\n",
    "# Optional: also fit NearestNeighbors on scaled features for similarity search\n",
    "nn_model = NearestNeighbors(metric=\"cosine\", algorithm=\"brute\")\n",
    "nn_model.fit(X_scaled)\n",
    "\n",
    "nn_path = os.path.join(models_dir, \"nn_model.pkl\")\n",
    "with open(nn_path, \"wb\") as f:\n",
    "    pickle.dump(nn_model, f)\n",
    "\n",
    "print(\"NearestNeighbors model saved to:\", nn_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "baf9ae2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample city: Bikaner\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>city</th>\n",
       "      <th>rating</th>\n",
       "      <th>rating_count</th>\n",
       "      <th>cost</th>\n",
       "      <th>cuisine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28884</th>\n",
       "      <td>461143</td>\n",
       "      <td>Paratha Party</td>\n",
       "      <td>Bikaner</td>\n",
       "      <td>4.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>North Indian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28667</th>\n",
       "      <td>234087</td>\n",
       "      <td>The Parivar Food</td>\n",
       "      <td>Bikaner</td>\n",
       "      <td>4.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>North Indian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28247</th>\n",
       "      <td>266809</td>\n",
       "      <td>Mr Curry Singh</td>\n",
       "      <td>Bikaner</td>\n",
       "      <td>4.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>North Indian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28871</th>\n",
       "      <td>318926</td>\n",
       "      <td>Dhaba by taj</td>\n",
       "      <td>Bikaner</td>\n",
       "      <td>4.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>North Indian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29552</th>\n",
       "      <td>309545</td>\n",
       "      <td>ROYAL HAVELI</td>\n",
       "      <td>Bikaner</td>\n",
       "      <td>4.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>North Indian</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id              name     city  rating  rating_count   cost  \\\n",
       "28884  461143     Paratha Party  Bikaner     4.0          50.0  250.0   \n",
       "28667  234087  The Parivar Food  Bikaner     4.0          50.0  250.0   \n",
       "28247  266809    Mr Curry Singh  Bikaner     4.0          50.0  250.0   \n",
       "28871  318926      Dhaba by taj  Bikaner     4.0          50.0  300.0   \n",
       "29552  309545      ROYAL HAVELI  Bikaner     4.0          50.0  300.0   \n",
       "\n",
       "            cuisine  \n",
       "28884  North Indian  \n",
       "28667  North Indian  \n",
       "28247  North Indian  \n",
       "28871  North Indian  \n",
       "29552  North Indian  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# === 7. Helper function inside notebook (for testing) ===\n",
    "\n",
    "def recommend_restaurants(\n",
    "    city: str,\n",
    "    min_rating: float,\n",
    "    max_cost: float,\n",
    "    preferred_cuisines: list,\n",
    "    top_n: int = 10\n",
    "):\n",
    "    \"\"\"\n",
    "    Simple recommendation: \n",
    "    1) Filter cleaned_df on city, rating, cost, cuisine.\n",
    "    2) Within filtered subset, use NearestNeighbors on encoded features.\n",
    "    \"\"\"\n",
    "\n",
    "    # Start from cleaned data\n",
    "    df_clean = df.copy().reset_index(drop=True)\n",
    "    df_enc = encoded_df.copy().reset_index(drop=True)\n",
    "\n",
    "    mask = (df_clean[\"city\"] == city)\n",
    "    mask &= (df_clean[\"rating\"] >= min_rating)\n",
    "    mask &= (df_clean[\"cost\"] <= max_cost)\n",
    "\n",
    "    # Cuisine filter: at least one of preferred cuisines should appear\n",
    "    if preferred_cuisines:\n",
    "        # Use mlb classes and encoded columns\n",
    "        cuisine_cols = [f\"cuisine_{c}\" for c in mlb.classes_]\n",
    "        for pc in preferred_cuisines:\n",
    "            col = f\"cuisine_{pc}\"\n",
    "            if col not in df_enc.columns:\n",
    "                # unknown cuisine; skip\n",
    "                continue\n",
    "\n",
    "        # Build mask: row has at least one of these cuisines = 1\n",
    "        cuisine_mask = np.zeros(len(df_enc), dtype=bool)\n",
    "        for pc in preferred_cuisines:\n",
    "            col = f\"cuisine_{pc}\"\n",
    "            if col in df_enc.columns:\n",
    "                cuisine_mask |= (df_enc[col] == 1)\n",
    "        mask &= cuisine_mask\n",
    "\n",
    "    filtered_idx = np.where(mask)[0]\n",
    "    if len(filtered_idx) == 0:\n",
    "        print(\"No restaurants found with given filters.\")\n",
    "        return df_clean.head(0)\n",
    "\n",
    "    X_scaled_full = scaler.transform(df_enc)\n",
    "    X_sub = X_scaled_full[filtered_idx]\n",
    "\n",
    "    nn = NearestNeighbors(metric=\"cosine\", algorithm=\"brute\")\n",
    "    nn.fit(X_sub)\n",
    "\n",
    "    # Query: we can use centroid of X_sub as a pseudo \"user profile\"\n",
    "    centroid = X_sub.mean(axis=0).reshape(1, -1)\n",
    "    distances, indices = nn.kneighbors(centroid, n_neighbors=min(top_n, len(filtered_idx)))\n",
    "\n",
    "    result_indices = filtered_idx[indices[0]]\n",
    "    cols_to_show = [\n",
    "    \"id\", \"name\", \"city\",\n",
    "    \"rating\", \"rating_count\", \"cost\",\n",
    "    \"cuisine\"\n",
    "    ]  #rating_clean,rating_count_clean,cost_clean\t\n",
    "    return df_clean.loc[result_indices, cols_to_show]\n",
    "\n",
    "# Quick test (example)\n",
    "sample_city = df[\"city\"].value_counts().idxmax()  # Fixed: most frequent city\n",
    "print(\"Sample city:\", sample_city)\n",
    "\n",
    "test_recos = recommend_restaurants(\n",
    "    city=sample_city,\n",
    "    min_rating=3.5,\n",
    "    max_cost=400,\n",
    "    preferred_cuisines=[],\n",
    "    top_n=5\n",
    ")\n",
    "test_recos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f859e740",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0627291",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3341443d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "244bb5bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4481fe8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4475e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be02c0af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e44169a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc8ae5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa5bf8aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35239494",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "025cc409",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bbbf4c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3382f275",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b371af9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d24572",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
